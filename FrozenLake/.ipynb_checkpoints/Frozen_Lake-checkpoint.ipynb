{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5723bc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c575dce4",
   "metadata": {},
   "source": [
    "### 4X4 GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a042b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLake-v1\",desc=None,map_name=\"4x4\", is_slippery=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4810eaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "action_space = env.action_space.n\n",
    "state_space = env.observation_space.n\n",
    "q_table = np.zeros((state_space,action_space))\n",
    "#print(q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91b6bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 10000\n",
    "max_steps_ep = 100\n",
    "\n",
    "lr = 0.1\n",
    "dr = 0.99\n",
    "\n",
    "expr_rate = 1\n",
    "max_expr_rate = 1\n",
    "min_expr_rate = 0.01\n",
    "expr_decay_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "104f59cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  processing\n",
      "2000  processing\n",
      "4000  processing\n",
      "6000  processing\n",
      "8000  processing\n",
      "Avg reward per thousand eps\n",
      "\n",
      "1000 :  0.05300000000000004\n",
      "2000 :  0.21000000000000016\n",
      "3000 :  0.4100000000000003\n",
      "4000 :  0.5500000000000004\n",
      "5000 :  0.6300000000000004\n",
      "6000 :  0.6610000000000005\n",
      "7000 :  0.6830000000000005\n",
      "8000 :  0.6950000000000005\n",
      "9000 :  0.6860000000000005\n",
      "10000 :  0.6750000000000005\n",
      "\n",
      "\n",
      " Q-Table\n",
      "\n",
      "[[0.53184115 0.49097931 0.51119436 0.50428542]\n",
      " [0.37726233 0.32869003 0.32006548 0.49359124]\n",
      " [0.40112169 0.37752708 0.39586975 0.46920416]\n",
      " [0.33183291 0.29995638 0.28053628 0.4456123 ]\n",
      " [0.55777753 0.39017337 0.44091821 0.27177551]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.25172546 0.16534112 0.21811238 0.14313956]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.46249299 0.41523555 0.37662811 0.59116805]\n",
      " [0.35466161 0.63057536 0.48316393 0.41609131]\n",
      " [0.62025451 0.41762332 0.31378225 0.41103318]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.40486996 0.51318754 0.79309814 0.35483521]\n",
      " [0.69726994 0.92493682 0.67733333 0.74785404]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "all_rewards = []\n",
    "for episode in range(num_episodes):\n",
    "    if episode%2000 == 0:\n",
    "        print(episode,\" processing\")\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    rewards_curr = 0\n",
    "    for step in range(max_steps_ep):\n",
    "        expr_thresh = random.uniform(0,1)\n",
    "        if expr_thresh > expr_rate:\n",
    "            action = np.argmax(q_table[state,:])\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        #update Q-table\n",
    "        q_table[state,action] = q_table[state,action]*(1 - lr) + \\\n",
    "        lr*(reward + dr*np.max(q_table[new_state,:]))\n",
    "        \n",
    "        state = new_state\n",
    "        rewards_curr += reward\n",
    "        if done == True:\n",
    "            break\n",
    "            \n",
    "    expr_rate = min_expr_rate + (max_expr_rate - min_expr_rate)* \\\n",
    "    np.exp(-expr_decay_rate*episode)\n",
    "    all_rewards.append(rewards_curr)\n",
    "rewards_per_thousand = np.split(np.array(all_rewards), num_episodes/1000)\n",
    "count = 1000\n",
    "print(\"Avg reward per thousand eps\\n\")\n",
    "for r in rewards_per_thousand:\n",
    "    print(count, \": \",str(sum(r/1000)))\n",
    "    count += 1000\n",
    "print(\"\\n\\n Q-Table\\n\")\n",
    "print(q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f954d2",
   "metadata": {},
   "source": [
    "### 8X8 GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b979cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLake-v1\",desc=None,map_name=\"8x8\", is_slippery=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9281a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = env.action_space.n\n",
    "state_space = env.observation_space.n\n",
    "q_table = np.zeros((state_space,action_space))\n",
    "#print(q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6610a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 50000\n",
    "max_steps_ep = 1000\n",
    "\n",
    "lr = 0.1\n",
    "dr = 0.99\n",
    "\n",
    "expr_rate = 1\n",
    "max_expr_rate = 1\n",
    "min_expr_rate = 0.01\n",
    "expr_decay_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb6df6e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  processing\n",
      "5000  processing\n",
      "10000  processing\n",
      "15000  processing\n",
      "20000  processing\n",
      "25000  processing\n",
      "30000  processing\n",
      "35000  processing\n",
      "40000  processing\n",
      "45000  processing\n",
      "Avg reward per thousand eps\n",
      "\n",
      "1000 :  0.002\n",
      "2000 :  0.005\n",
      "3000 :  0.016000000000000007\n",
      "4000 :  0.010000000000000002\n",
      "5000 :  0.03300000000000002\n",
      "6000 :  0.03200000000000002\n",
      "7000 :  0.035000000000000024\n",
      "8000 :  0.05100000000000004\n",
      "9000 :  0.06800000000000005\n",
      "10000 :  0.07700000000000005\n",
      "11000 :  0.11400000000000009\n",
      "12000 :  0.1230000000000001\n",
      "13000 :  0.1420000000000001\n",
      "14000 :  0.1460000000000001\n",
      "15000 :  0.18700000000000014\n",
      "16000 :  0.18300000000000013\n",
      "17000 :  0.22400000000000017\n",
      "18000 :  0.2460000000000002\n",
      "19000 :  0.2440000000000002\n",
      "20000 :  0.2570000000000002\n",
      "21000 :  0.2840000000000002\n",
      "22000 :  0.32700000000000023\n",
      "23000 :  0.33000000000000024\n",
      "24000 :  0.36300000000000027\n",
      "25000 :  0.36100000000000027\n",
      "26000 :  0.3730000000000003\n",
      "27000 :  0.36600000000000027\n",
      "28000 :  0.4170000000000003\n",
      "29000 :  0.43800000000000033\n",
      "30000 :  0.3950000000000003\n",
      "31000 :  0.4240000000000003\n",
      "32000 :  0.4240000000000003\n",
      "33000 :  0.4120000000000003\n",
      "34000 :  0.44300000000000034\n",
      "35000 :  0.5110000000000003\n",
      "36000 :  0.47900000000000037\n",
      "37000 :  0.43500000000000033\n",
      "38000 :  0.4990000000000004\n",
      "39000 :  0.47800000000000037\n",
      "40000 :  0.5130000000000003\n",
      "41000 :  0.5350000000000004\n",
      "42000 :  0.5170000000000003\n",
      "43000 :  0.5220000000000004\n",
      "44000 :  0.5050000000000003\n",
      "45000 :  0.4830000000000004\n",
      "46000 :  0.5680000000000004\n",
      "47000 :  0.5260000000000004\n",
      "48000 :  0.5070000000000003\n",
      "49000 :  0.5210000000000004\n",
      "50000 :  0.5770000000000004\n",
      "\n",
      "\n",
      " Q-Table\n",
      "\n",
      "[[3.99033811e-01 4.34103014e-01 4.10951964e-01 4.10531835e-01]\n",
      " [4.13373210e-01 4.14309310e-01 4.47746071e-01 4.18329234e-01]\n",
      " [4.26559041e-01 4.37161541e-01 4.70419513e-01 4.28748319e-01]\n",
      " [4.49864020e-01 4.47268831e-01 4.90808967e-01 4.51608108e-01]\n",
      " [4.76416104e-01 4.72106634e-01 5.09241286e-01 4.67956228e-01]\n",
      " [4.83287568e-01 4.90564591e-01 5.24337053e-01 4.90818100e-01]\n",
      " [5.14162509e-01 5.20580247e-01 5.42646700e-01 5.23520299e-01]\n",
      " [5.27068508e-01 5.46511737e-01 5.19977054e-01 5.21994923e-01]\n",
      " [3.89951594e-01 4.06272129e-01 3.86864508e-01 4.33963172e-01]\n",
      " [3.96290763e-01 3.95929718e-01 4.13629995e-01 4.48229364e-01]\n",
      " [4.00208907e-01 4.18160201e-01 4.23106062e-01 4.64604814e-01]\n",
      " [2.29181994e-01 2.83373397e-01 2.56695778e-01 4.80913914e-01]\n",
      " [4.38602237e-01 4.32895906e-01 4.49195155e-01 4.92969581e-01]\n",
      " [4.66703830e-01 4.63968743e-01 5.18575979e-01 4.85771522e-01]\n",
      " [5.29113451e-01 5.33177343e-01 5.55181176e-01 5.32350421e-01]\n",
      " [5.62257908e-01 5.36499528e-01 5.48306588e-01 5.36837440e-01]\n",
      " [3.52403800e-01 3.48700107e-01 3.53153091e-01 3.81418273e-01]\n",
      " [3.43208982e-01 3.42688494e-01 3.37191938e-01 3.74322573e-01]\n",
      " [3.61939795e-01 2.28485654e-01 2.24269515e-01 2.85080882e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.85539627e-01 2.53721009e-01 3.98113068e-01 3.13458297e-01]\n",
      " [3.33672839e-01 3.23710603e-01 2.66190520e-01 4.98892075e-01]\n",
      " [5.50107339e-01 5.45536152e-01 5.85981366e-01 5.39321522e-01]\n",
      " [5.82677304e-01 6.04827296e-01 5.84809746e-01 5.77639824e-01]\n",
      " [3.19915260e-01 3.18690311e-01 3.18955819e-01 3.44069786e-01]\n",
      " [2.94477932e-01 2.87739187e-01 2.86515886e-01 3.44982421e-01]\n",
      " [2.23626334e-01 2.12977809e-01 2.31339814e-01 3.00466390e-01]\n",
      " [8.69822201e-02 1.48496976e-01 7.64434355e-02 9.76287261e-02]\n",
      " [2.48508672e-01 1.52692478e-01 1.68634820e-01 1.34999542e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.07577380e-01 3.28676337e-01 5.85732518e-01 5.00296092e-01]\n",
      " [6.33006404e-01 6.30073870e-01 6.36582483e-01 5.93292329e-01]\n",
      " [2.70119050e-01 2.63187011e-01 2.70749895e-01 2.97197956e-01]\n",
      " [2.09200538e-01 2.01606285e-01 1.82041304e-01 2.34351658e-01]\n",
      " [9.18648550e-02 8.50366203e-02 8.78878595e-02 7.73570852e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.36872244e-01 1.54555423e-01 2.49880130e-01 1.99334534e-01]\n",
      " [9.99741840e-02 3.44336682e-01 2.27694701e-01 1.29789057e-01]\n",
      " [3.01925815e-01 3.62353742e-01 3.64372863e-01 5.85093998e-01]\n",
      " [6.77781093e-01 6.79679145e-01 6.85043435e-01 6.47337032e-01]\n",
      " [2.64379987e-01 1.22862543e-01 1.36865745e-01 1.72407250e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.30816151e-03 3.24925726e-02 3.49672195e-02 1.92113634e-02]\n",
      " [8.98482518e-02 9.72507130e-02 1.11456899e-01 1.77059485e-01]\n",
      " [2.36710991e-01 1.18729005e-01 1.76008455e-01 1.74153698e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.42884433e-01 3.26864921e-01 7.79796335e-01 6.21642191e-01]\n",
      " [2.29782770e-01 6.20772953e-02 5.23953883e-02 5.86073555e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [4.16732137e-03 2.45301734e-03 2.38862034e-02 2.51292765e-03]\n",
      " [2.79368242e-03 4.88352727e-03 6.86217896e-03 2.27768226e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.19445062e-01 1.39753970e-01 1.28691791e-01 4.96806420e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [6.09028524e-01 3.50299081e-01 8.90866918e-01 4.80783774e-01]\n",
      " [2.14616312e-01 4.40248848e-02 3.82965150e-02 7.60232073e-02]\n",
      " [6.16100514e-02 1.04443574e-02 1.01743763e-03 5.11557416e-04]\n",
      " [1.90277893e-03 4.40693044e-02 3.20146398e-03 1.62264848e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [3.84172116e-02 1.65608918e-01 0.00000000e+00 2.46072950e-02]\n",
      " [1.86481623e-01 5.19896443e-01 3.98889560e-01 2.07941095e-01]\n",
      " [2.56696174e-01 8.32021753e-01 3.49093516e-01 3.30068275e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "all_rewards = []\n",
    "for episode in range(num_episodes):\n",
    "    if episode%5000 == 0:\n",
    "        print(episode,\" processing\")\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    rewards_curr = 0\n",
    "    for step in range(max_steps_ep):\n",
    "        expr_thresh = random.uniform(0,1)\n",
    "        if expr_thresh > expr_rate:\n",
    "            action = np.argmax(q_table[state,:])\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        #update Q-table\n",
    "        q_table[state,action] = q_table[state,action]*(1 - lr) + \\\n",
    "        lr*(reward + dr*np.max(q_table[new_state,:]))\n",
    "        \n",
    "        state = new_state\n",
    "        rewards_curr += reward\n",
    "        if done == True:\n",
    "            break\n",
    "            \n",
    "    expr_rate = min_expr_rate + (max_expr_rate - min_expr_rate)* \\\n",
    "    np.exp(-expr_decay_rate*episode)\n",
    "    all_rewards.append(rewards_curr)\n",
    "rewards_per_thousand = np.split(np.array(all_rewards), num_episodes/1000)\n",
    "count = 1000\n",
    "print(\"Avg reward per thousand eps\\n\")\n",
    "for r in rewards_per_thousand:\n",
    "    print(count, \": \",str(sum(r/1000)))\n",
    "    count += 1000\n",
    "print(\"\\n\\n Q-Table\\n\")\n",
    "#print(q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6df3c2",
   "metadata": {},
   "source": [
    "### DISPLAY RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40caaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(3):\n",
    "    state = env.reset()\n",
    "    print(\"******EPISODE \",episode+1,\"******\\n\\n\")\n",
    "    time.sleep(3)\n",
    "    for step in range(max_steps_ep):\n",
    "        clear_output(wait = True)\n",
    "        env.render()\n",
    "        time.sleep(0.3)\n",
    "        \n",
    "        action = np.argmax(q_table[state,:])\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        if done:\n",
    "            clear_output(wait = True)\n",
    "            env.render()\n",
    "            if reward == 1:\n",
    "                print(\"you have reached the goal\")\n",
    "                time.sleep(3)\n",
    "            else:\n",
    "                print(\"you fell through a hole\")\n",
    "            break\n",
    "        state = new_state\n",
    "    env.reset()\n",
    "    env.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a070cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
